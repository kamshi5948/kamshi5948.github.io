
# Study1

---

## 1. 장애 및 부하 상황 대응방안

### 1.1 사전 예방 체계

| 구분 | 주요 내용 |
|------|------------|
| **모니터링 체계 구축** | - **Prometheus + Grafana**: CPU, Memory, Network, DB connection pool 등 실시간 모니터링<br>- **Loki + Promtail**: 로그 수집/검색 통합<br>- **Alertmanager**: 임계치 도달 시 Slack, 메일, SMS 알림 발송 |
| **임계치 설정 예시** | - CPU 사용률 80% 초과 시 알림<br>- HTTP 5xx 비율 2% 초과 시 경보<br>- DB Connection Pool 사용률 90% 초과 시 경고 |
| **장애 리허설 (Chaos Engineering)** | - **Chaos Mesh, Gremlin**으로 장애 상황(노드 종료, 네트워크 단절 등) 주기적 시뮬레이션<br>- 장애 대응팀 정기 훈련 (DR Drill) |

---

### 1.2 장애 발생 시 단계별 대응

| 단계 | 조치 내용 | 사례 |
|------|------------|-------|
| **1단계 - 탐지** | 모니터링 시스템에서 경보 감지 | **예시:** Prometheus에서 CPU 사용률 95% 초과 경보 발생 |
| **2단계 - 식별** | 영향 범위 및 서비스 식별 | **예시:** 특정 API 응답시간 지연, “/order/checkout” 엔드포인트 집중 부하 확인 |
| **3단계 - 격리** | 문제 인스턴스 트래픽 차단 | **예시:** Kubernetes에서 헬스체크 실패 Pod 자동 격리 (`kubectl cordon` 또는 HPA 스케일 아웃) |
| **4단계 - 복구** | 서비스 재기동, 캐시 초기화, DB Failover 수행 | **예시:** Redis 캐시 메모리 누수로 인한 장애 → Redis Flush 후 Pod 재시작 |
| **5단계 - 원인 분석** | RCA 보고서 작성 및 개선 | **예시:** JVM GC tuning 부족으로 Full GC 빈번 발생 → Heap size 조정 및 G1GC로 변경 |

---

### 1.3 장애 유형별 대응 사례

#### (1) 애플리케이션 메모리 누수

- **발생 상황:** 서비스 지속 구동 중, 응답속도 점진적 하락 및 OOM 발생  
- **원인:** 객체 미해제, 캐시 반복 누적 (Ehcache / ConcurrentHashMap 미정리)  
- **대응:**  
  - Prometheus 메모리 지표 기반 자동 경고  
  - Kubernetes HPA + Liveness Probe로 자동 재시작  
  - Leak 발생 코드 수정 후 Canary 배포  
- **사후 조치:** Heap dump 분석 및 코드 리뷰 프로세스 강화

---

#### (2) DB Connection Pool 고갈

- **발생 상황:** 피크 시간대(오전 11시~12시)에 DB 커넥션 수 초과로 API Timeout 다수 발생  
- **원인:** 커넥션 미반납 또는 트랜잭션 미종료  
- **대응:**  
  - HikariCP maxPoolSize 상향 조정  
  - Connection leak detection 활성화 (`leakDetectionThreshold=20000`)  
  - DB Read Replica 분리로 부하 분산  
- **사후 조치:** 커넥션 사용 모니터링 대시보드 추가 (Grafana + MySQL Exporter)

---

#### (3) Redis 장애 (캐시 서버 다운)

- **발생 상황:** Redis Pod 재시작 중 TTL 데이터 손실 → 응답 지연 발생  
- **원인:** 세션 캐시가 휘발성으로 관리됨  
- **대응:**  
  - 애플리케이션에서 캐시 미스 시 Graceful fallback 로직 적용  
  - Redis Sentinel을 통한 Failover 구성  
  - Redis AOF(Append Only File) 모드 활성화  
- **사후 조치:** 캐시 장애 시 본 DB로 자동 fallback하도록 코드 표준화

---

#### (4) Kubernetes 노드 장애

- **발생 상황:** 특정 Node의 GPU Driver 오류로 Pod 다수 CrashLoopBackOff 발생  
- **대응:**  
  - Node cordon 및 drain 처리 후 Pod 자동 재스케줄링  
  - Cluster Autoscaler로 새 Node 자동 추가  
  - Loki로 장애 노드 로그 수집 후 원인 분석  
- **사후 조치:** GPU Driver DaemonSet 업데이트 자동화 (ArgoCD Sync)

---

#### (5) 트래픽 급증 (이벤트, 프로모션 등)

- **발생 상황:** 마케팅 이벤트로 10배 트래픽 급증  
- **대응:**  
  - HPA 기준 지표(CPU, Request Count)에 따라 자동 스케일아웃  
  - CDN (CloudFront)으로 정적 콘텐츠 캐싱 강화  
  - Kafka 기반 비동기 주문 큐 적용  
  - DB Read Replica AutoScaling 활성화  
- **사후 조치:** 이벤트 전 사전 부하테스트(K6, Locust) 자동화 파이프라인 도입

---

## 2. 아키텍처 고도화 방안

### 2.1 개선 목표

| 목표 | 내용 |
|------|------|
| **안정성 향상** | 멀티 AZ, Auto Healing, DR Site 구축 |
| **확장성 강화** | Kubernetes + HPA + Cluster Autoscaler |
| **성능 개선** | 캐시 계층 분리, CDN, 비동기 메시징 |
| **관측성 강화** | Logs, Metrics, Traces 통합 (OpenTelemetry 기반) |
| **보안성 확보** | Vault, RBAC, TLS 암호화 |

---

### 2.2 권장 아키텍처 (Kubernetes 기반 예시)

```
[User]
  ↓
[API Gateway (Kong/Istio)]
  ↓
[Service Mesh]
  ├── User Service
  ├── Order Service
  ├── Payment Service
  ↓
[Async Queue (Kafka)]
  ↓
[DB Layer]
  ├── MySQL Primary/Replica
  ├── Redis Cluster (AOF Enabled)
  ↓
[Observability Layer]
  ├── Prometheus + Grafana
  ├── Loki + Tempo
  ├── OpenTelemetry Collector
```

---

### 2.3 운영 자동화 및 배포 고도화

| 구분 | 주요 내용 |
|------|------------|
| **CI/CD 자동화** | - GitLab CI, ArgoCD 이용<br>- Canary Deployment + Blue/Green 지원 |
| **IaC (Infrastructure as Code)** | - Terraform + Helm Chart 기반 자동 프로비저닝 |
| **자동복구(Self-Healing)** | - Liveness Probe, Readiness Probe, Auto Rollback |
| **DR/백업 전략** | - DB Snapshot + Object Storage 백업 주기화<br>- DR Site에서 자동 복구 테스트 |

---

## 3. 기대 효과

| 구분 | 기대 효과 |
|------|-------------|
| **운영 안정성** | 장애 자동 탐지 및 자가 복구로 MTTR 단축 |
| **성능 향상** | 캐시/비동기 처리로 TPS 2~5배 향상 |
| **운영 효율화** | 로그, 모니터링, 배포 자동화 |
| **서비스 신뢰도 향상** | 무중단 배포 및 재해복구 체계 확립 |

---

## 4. 추가 제언

1. **SRE (Site Reliability Engineering) 도입**  
   - 장애 원인 분석 및 재발 방지 문화 확립  
   - SLA/SLO 기반 지표 관리

2. **AIOps 기반 예측형 운영 체계 구축**  
   - 머신러닝 기반 부하 예측 및 이상 탐지 자동화

3. **Zero Downtime Release 체계 강화**  
   - Blue/Green + Canary 혼합 배포 구조로 장애 리스크 최소화

---

**Prepared by:** 기술 아키텍처팀  
**Version:** 1.1  
**Date:** 2025-10-29
