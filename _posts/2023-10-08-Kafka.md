## 특징
	- 대용량의 실시간 로그처리에 특화된 아키텍처 설계를 통하여 기존 메시징 시스템보다 우수한 TPS를 보여주고 있다.
	- 기존의 메시징 시스템에서는 broker가 consumer에게 메시지를 push해 주는 방식인데 반해, 
	  Kafka는 consumer가 broker로부터 직접 메시지를 가지고 가는 pull 방식으로 동작한다. 
	  따라서 consumer는 자신의 처리능력만큼의 메시지만 broker로부터 가져오기 때문에 최적의 성능을 낼 수 있다.
	- 기존의 push 방식의 메시징 시스템에서는 broker가 직접 각 consumer가 어떤 메시지를 처리해야 하는지 계산하고 어떤 메시지를 처리 중인지 트랙킹하였는데, 
	  Kafka에서는 consumer가 직접 필요한 메시지를 broker로부터 pull하므로 broker의 consumer와 메시지 관리에 대한 부담이 경감되었다. 
	  메시지를 pull 방식으로 가져오므로, 메시지를 쌓아두었다가 주기적으로 처리하는 batch consumer의 구현이 가능하다.

## <span style="background-color:#fff5b1">kafka Dead Letter Queue(DLQ, DLT)</span>
	- 특징
		* AWS SQS에서는 Dead Letter Queue(DLQ)를 손쉽게 제공하고 연결할 수 있도록 합니다.
	      메시지가 실패하는 경우 재처리를 몇 번 할지도 console에서 간편하게 설정할 수 있습니다.
	      Kafka의 경우 메시지 처리에 실패하면 Dead Letter Queue(DLQ)를 어떻게 관리할 수 있을까요?
	      Kafka에서는 DLQ대신 DLT라는 개념을 사용합니다.
	      DLT는 Dead Letter Topic의 약자입니다.

	- DLT Consumer 구현
		* 이후 Producer에서 메시지를 전송하면 1초 간격으로 2회 동안 재시도를 수행하고 Kafka DLQ consumer가 메시지를 읽어 들입니다.
		  DLT가 발생하면 error 로그를 발생시키거나, 개발자에게 알림을 주도록 하여 처리할 수 있을 것 같습니다.

## 기본구성 요소
	- Kafka는 발행-구독(publish-subscribe) 모델을 기반으로 동작하며 크게 producer, consumer, broker로 구성된다.


## 카프카 Messaging sementics
	- At-Most-Once
		* 실패나 타임아웃 등이 발생하면 메시지를 버릴 수 있다. 데이터가 일부 누락되더라도 영향이 없는 경우엔 대량처리 및 짧은 주기의 전송 서비스에 유용할 수 있다.
		* 자동커밋 사용
	- At-Least-Once
		* 메시지가 최소 1번 이상 전달되는 것을 보장한다. 실패나 타임아웃 등이 발생하면 메시지를 다시 전송하며, 이 경우엔 동일한 메시지가 중복으로 처리될 수 있다.
		* Producer : Producer-Broker 사이의 ack 소실
			- Producer는 Broker에 메시지를 전송하고 ack를 수신받는다. 만약 네트워크 상에서 ack가 소실/지연되어 수신받는데에 실패할 경우, Producer는 메시지 전송이 실패했다고 판단하여 재전송하게 된다. 
			  즉, 동일한 메시지가 중복 전송될 수 있다.
		* Consumer : offset 갱신 실패
			- Consumer가 메시지를 읽고 DB에 저장한 후에 offset을 갱신하기 전에 장애가 발생할 경우, Consumer는 재시작되었을 때 갱신되지 않은 offset을 기준으로 메시지를 읽어오게 된다. 
			  즉, 이미 DB에 저장된 메시지를 중복으로 가져오게 된다.
			- 해결방안
				* consumer는 결국 중복으로 subscribe된 메세지에 대한 처리를 실제 로직에서는 중복 방지될 수 있게, 즉 멱등성이 보장될 수 있도록 구현해야 한다.
				  임의의 event-id를 기준으로 동일한 message에 대해서 insert는 skip
				  update 처리인 경우는 메세지 순서를 고려해야 하기 때문에 producer에서 메세지 publish시점 정보를 담은 publish_at 정보를 활용, 순서를 검증할 수 있다.
				  consumer offset commit 방식은 수동으로 설정하여 로직이 성공했을 떄 수동으로 offset commit을 하는 방식을 적용한다.(ex. commitSync(), acknowledge())

## 성능 튜닝
	- subscribe 시 성능을 향상시키기 위한 점검 방식 및 방안
		* 토픽 타입 : 배치, 온라인
		* 온라인은 실시간이나 준실시간을 요구하는 성능이 필요한 토픽
		* 배치는 많은 데이터를 특정 시간 안에 처리해야 하는 성능이 필요한 토픽
		* 성능 튜닝을 위한 사전 조건 : Publish 최대 메시지(건), Subscribe 구독 목표 시간(분) 요청사항에 기재
		* 목표 TPS를 확인하고 필요한 파티션 수 산정
	- 파티션 증설
		* kafka의 파티션의 수를 증가시키는 것은 시스템의 처리량을 높이고, 고가용성을 향상시키는 중요한 방법
		  파티션은 kafka의 메시지를 저장하는 기본 단위로 각 토픽은 하나 이상의 파티션을 구성됨
		  파티션의 수가 증가시키면 메시지를 병렬로 처리할 수 있는 범위가 확대되어 시스템의 전반적인 처리량이 증가됨
		  각 파티션은 독립적으로 복제되므로 파티션의 수를 증가시키면 내결함성과 고가용성도 향상됨
		* 증설기준
			- 처리량
			- 고가용성
			- 성능과 용량의 제약사항 : 브로커의 메모리 부하, 디스크 용량, 네트워크 트래픽 등 시스템의 성능 및 제약사항 고려해야함
				파티션 수가 많아질수록 이러한 제약사항이 더욱 중요해짐
				하지만 파티션 수를 무작정 증가시키는 것은 바람직하지 않음, 파티션 수가 많아질수록 브로커가 유지해야되는 연결 및 메타데이터의 양이 증가하므로
				브로커의 메모리 부하와 네트워크 부하가 증가하게 됨, 따라서 파티션 수를 증가시킬때에는 이러한 부작용을 고려하여 적절한 균형을 찾아야함
				또한 파티션의 수가 증가시키면 메시지의 순서 보장이 어려워 질 수 있음, kafka는 같은 파티션 내에서만 순서를 보장하기 때문에 파티션의 수를 조정하면
				메시지의 순서가 바뀔 수 있음, 특히 메시지의 순서가 중요한 어플리케이션에서는 주의해야함
				증설한 파티션의 수와 Consumer와 1:1로 구성해야 최대한의 성능을 보장할 수 있음, 하지만 자원이 무한하지 않기 때문에 여러번의 테스트를 수행하여 최적의 값을 찾아야함
			- 응답시간 개선
				모니터링 툴을 활용하여 어플리케이션에서 메시지를 처리하는 메시지 처리 시간을 측정함
			- 관리방안
				프로젝트에는 여러 subscribe 성능 개선 요청을 하기 때문에 관리나 이력을 남기는 것이 중요함, jira와 같은 이슈관리 툴이 필요함
			- 모니터링툴
				* promethus : 브로커와 컨슈머의 메트릭 데이터를 수집하고 저장 
				* grafana : 수집된 데이터를 시각화하여 실시간으로 성능 모니터링이 가능함(메시지 처리량, 지연 시간, 파티션 리더 등) 
				  지표들을 모니터링하여 성능 문제를 식별하고 최적화할 수 있음
				* lag-exporter : 카프카 컨슈머 그룹의 지연 정보를 수집하고 Promethus로 내보내는 오픈 소스 도구, 주기적으로 컨슈머 그룹의 오프셋 정보를 확인하고 lag 정보를 업데이트함
	- 주의사항
		* 파티션 증설의 한계(컨슈머 리밸런싱)
			- 일시적으로 메시지 처리 지연 발생
			- 메시지 분포의 불균형 초래
			- 발행과 구독을 중지하고 파티션 증설을 진행하면 리스크를 줄일 수 있음
			- 파티션 한개치 : 30개(프로젝트마다 다를 수 있음, 많아질수록 컨슈머 리밸런싱 시간이 길어짐, 파티션을 너무 늘리면 Pod 자원수도 고려해야함)
		* 파티션 키
			- 카프카에서 메시지를 분산 저장하기 위해서 사용하는 값
			- 메시지가 어떤 파티션에 저장될지 결정하는 역할
			- 일반적으로 메시지의 특정 속성이나 식별자로 선택
			- 동일한 파티션 키를 가진 메시지는 동일한 파티션에 저장되며 이를 통해 관련된 데이터가 동일한 파티션에 위치하여 순서와 관련된 처리를 보장할 수 있음
			- 메시지의 분산성과 균형을 유지하기 위해 주의 필요, 만약 파티션 키가 불균형하게 선택되면 일부 파티션에는 다른 파티션보다 많은 메시지가 쌓이게 됨
			  이는 해당 파티션의 부하가 증가하고 처리량이 제한될 수 있는 원인이 됨, 클러스터의 성능과 확장성에 영향을 미칠 수 있음
			- 파티션 키 선택에 있어서 데이터의 분포, 동일한 순서 유지, 일관성 등을 고려해서 균형있는 분산을 유지할 수 있는 값들을 선택하는 것이 중요함
		* Concurrency
			- 어플리케이션에서 병렬로 처리하는 경우에는 파티션 키를 지정했어도 순서 보장의 의미가 없음
			- 어플리케이션에서 병렬 처리를 요구하는 경우에는 파티션 키가 없는 대상에 적용해야함
		* 설정값
			- config max.poll.records : 한번 poll 수행시 컨슈머가 한번에 가져올 최대 레코드 수(default: 500) 
			  이 설정값은 소비자의 처리량과 레이턴시에 직접적인 영향을 미침
			  값이 높으면 처리량이 증가하지만 동시에 레코드 처리시간이 증가할 수 있음(구독성능을 최적화 하기 위해 이 값도 적절하게 조정해야함)	

## Producer, Consumer 성능 튜닝
	- Producer
		* 파티션 수 증가
		* Acks : 메시지 유실의 민감도에 따라 적용 (all/1/0)
		* buffer.memory : 전송할 메시지를 보관하는 메모리 크기(Bytes), 메시지 발생건 수가 많고, 발행할 토픽의 파티션 개수가 많으면 해당값 증가 필요
		* compression.type : 압축을 통해 pub/sub 메시지 사이즈를 줄임으로써 네트워크 송수신의 효율을 높여 성능을 확보함(단 압축에 따른 CPU 자원이 추가로 필요하여 시스템 자원 사용률을 확인해야함)
		* batch.size : 다수의 메시지를 묶어 recordbatch 형태로 kafka에 publish함, 배치형태의 pub/sub에 유리함(default: 16kb)
		* linger.ms : producer가 batch.size만큼의 데이터를 적재하기 위해 대기하는 시간, 배치성격의 데이터 묶음의 전송이 필요한 경우 해당값 증가 필요
		* max.request.size : 한번에 전송하기 위한 recordbatch의 사이즈, 메시지가 큰 데이터를 지속적으로 발행하는 경우 해당값 증가 필요
		



## 메시지 중복 처리

## 참고자료
[kAFKA](https://junuuu.tistory.com/800)

[CQRS](https://mslim8803.tistory.com/73)

[MS-CQRS](https://learn.microsoft.com/ko-kr/azure/architecture/patterns/cqrs)

[MS-비동기](https://learn.microsoft.com/ko-kr/previous-versions/msp-n-p/dn589781(v=pandp.10)
